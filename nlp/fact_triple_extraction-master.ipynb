{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\"\"\"\n",
    "文本中事实三元组抽取\n",
    "python *.py input.txt output.txt begin_line end_line\n",
    "\"\"\"\n",
    "# 原作者\n",
    "__author__ = \"tianwen jiang\"\n",
    "# 原代码版本为Python2.7\n",
    "# 以下代码运行在Python3.6\n",
    "# 大部分注释是我自己加的，不一定准确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyltp import Segmentor, Postagger, Parser, NamedEntityRecognizer# 需装Python后再下载模型，此次运行的模型版本为3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载LTP模型... ...\n",
      "加载模型完毕。\n"
     ]
    }
   ],
   "source": [
    "print(\"正在加载LTP模型... ...\")\n",
    "# Set your own model path\n",
    "MODELDIR=\"E:\\pyltp_model\\ltp_data_v3.4.0\"\n",
    "\n",
    "segmentor = Segmentor()\n",
    "# segmentor.load(os.path.join(MODELDIR, \"cws.model\"))\n",
    "cws_model_path=os.path.join(MODELDIR, \"cws.model\")\n",
    "segmentor.load_with_lexicon(cws_model_path, './dict.txt') #请把字典文件放进当前文件夹\n",
    "               \n",
    "postagger = Postagger()\n",
    "postagger.load(os.path.join(MODELDIR, \"pos.model\"))\n",
    "\n",
    "parser = Parser()\n",
    "parser.load(os.path.join(MODELDIR, \"parser.model\"))\n",
    "\n",
    "recognizer = NamedEntityRecognizer()\n",
    "recognizer.load(os.path.join(MODELDIR, \"ner.model\"))\n",
    "\n",
    "#labeller = SementicRoleLabeller()\n",
    "#labeller.load(os.path.join(MODELDIR, \"srl/\"))\n",
    "\n",
    "print(\"加载模型完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file_name = \"input.txt\"# 输入你想要抽取三元组的文件\n",
    "out_file_name = \"out_file.txt\"# 保存三元组文件\n",
    "begin_line = 1\n",
    "end_line = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(sys.argv) > 1:\n",
    "#     in_file_name = sys.argv[1]\n",
    "\n",
    "# if len(sys.argv) > 2:\n",
    "#     out_file_name = sys.argv[2]\n",
    "\n",
    "# if len(sys.argv) > 3:\n",
    "#     begin_line = int(sys.argv[3])\n",
    "\n",
    "# if len(sys.argv) > 4:\n",
    "#     end_line = int(sys.argv[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_start(in_file_name, out_file_name, begin_line, end_line):\n",
    "    \"\"\"\n",
    "    事实三元组抽取的总控程序\n",
    "    Args:\n",
    "        in_file_name: 输入文件的名称\n",
    "        #out_file_name: 输出文件的名称\n",
    "        begin_line: 读文件的起始行\n",
    "        end_line: 读文件的结束行\n",
    "    \"\"\"\n",
    "    in_file = open(in_file_name, 'r',encoding='utf-8')\n",
    "    out_file = open(out_file_name, 'a',encoding='utf-8')\n",
    "    \n",
    "    line_index = 1\n",
    "    sentence_number = 0\n",
    "    text_line = in_file.readline() # 读取一行\n",
    "    while text_line:\n",
    "        # 读取下一行----------------------------\n",
    "        if line_index < begin_line:\n",
    "            text_line = in_file.readline()\n",
    "            line_index += 1\n",
    "            continue\n",
    "        if end_line != 0 and line_index > end_line:\n",
    "            break\n",
    "        sentence = text_line.strip()\n",
    "        # --------------------------------------\n",
    "        if sentence == \"\" or len(sentence) > 1000: # 不读取空行和长度超过1000的行\n",
    "            text_line = in_file.readline()\n",
    "            line_index += 1\n",
    "            continue\n",
    "        try:\n",
    "            fact_triple_extract(sentence, out_file) \n",
    "            out_file.flush() #把缓冲区的文件强制写出，这里可能可以优化\n",
    "        except:\n",
    "            pass\n",
    "        sentence_number += 1\n",
    "#         if sentence_number % 50 == 0:\n",
    "#             print(\"完成50个句子的抽取\")\n",
    "        text_line = in_file.readline()\n",
    "        line_index += 1\n",
    "    in_file.close()\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_triple_extract(sentence, out_file):\n",
    "    \"\"\"\n",
    "    对于给定的句子进行事实三元组抽取\n",
    "    Args:\n",
    "        sentence: 要处理的语句\n",
    "    \"\"\"\n",
    "    # 切割句子\n",
    "    words = segmentor.segment(sentence)\n",
    "    # 词性标注\n",
    "    postags = postagger.postag(words)\n",
    "    # 命名实体识别\n",
    "    netags = recognizer.recognize(words, postags)\n",
    "    # 依存句法分析，其中已有模型可将句子中的主谓宾等结构抽取出来\n",
    "    arcs = parser.parse(words, postags)\n",
    "\n",
    "    child_dict_list = build_parse_child_dict(words, postags, arcs)\n",
    "    for index in range(len(postags)):\n",
    "        # 抽取以谓词为中心的事实三元组\n",
    "        if postags[index] == 'v':\n",
    "            child_dict = child_dict_list[index]\n",
    "            # 主谓宾\n",
    "            if   ('SBV') in child_dict and  ('VOB') in child_dict:\n",
    "                e1 = complete_e(words, postags, child_dict_list, child_dict['SBV'][0])\n",
    "                r = words[index]\n",
    "                e2 = complete_e(words, postags, child_dict_list, child_dict['VOB'][0])\n",
    "                out_file.write(\"%s, %s, %s\\n\" % (e1, r, e2)) #此处三元组的输出格式有待规范\n",
    "                out_file.flush()\n",
    "            # 定语后置，动宾关系\n",
    "            if arcs[index].relation == 'ATT':\n",
    "                if  ('VOB') in child_dict:\n",
    "                    e1 = complete_e(words, postags, child_dict_list, arcs[index].head - 1)\n",
    "                    r = words[index]\n",
    "                    e2 = complete_e(words, postags, child_dict_list, child_dict['VOB'][0])\n",
    "                    temp_string = r+e2\n",
    "                    if temp_string == e1[:len(temp_string)]:\n",
    "                        e1 = e1[len(temp_string):]\n",
    "                    if temp_string not in e1:\n",
    "                        out_file.write(\"%s, %s, %s\\n\" % (e1, r, e2)) #此处三元组的输出格式有待规范\n",
    "                        out_file.flush()\n",
    "            # 含有介宾关系的主谓动补关系\n",
    "            if  ('SBV') in child_dict and  ('CMP') in child_dict:\n",
    "                #e1 = words[child_dict['SBV'][0]]\n",
    "                e1 = complete_e(words, postags, child_dict_list, child_dict['SBV'][0])\n",
    "                cmp_index = child_dict['CMP'][0]\n",
    "                r = words[index] + words[cmp_index]\n",
    "                if  ('POB') in child_dict_list[cmp_index]:\n",
    "                    e2 = complete_e(words, postags, child_dict_list, child_dict_list[cmp_index]['POB'][0])\n",
    "                    out_file.write(\"%s, %s, %s\\n\" % (e1, r, e2)) #此处三元组的输出格式有待规范\n",
    "                    out_file.flush()\n",
    "\n",
    "        # 尝试抽取命名实体有关的三元组\n",
    "        if netags[index][0] == 'S' or netags[index][0] == 'B':\n",
    "            ni = index\n",
    "            if netags[ni][0] == 'B':\n",
    "                while netags[ni][0] != 'E':\n",
    "                    ni += 1\n",
    "                e1 = ''.join(words[index:ni+1])\n",
    "            else:\n",
    "                e1 = words[ni]\n",
    "            if arcs[ni].relation == 'ATT' and postags[arcs[ni].head-1] == 'n' and netags[arcs[ni].head-1] == 'O':\n",
    "                r = complete_e(words, postags, child_dict_list, arcs[ni].head-1)\n",
    "                if e1 in r:\n",
    "                    r = r[(r.index(e1)+len(e1)):]\n",
    "                if arcs[arcs[ni].head-1].relation == 'ATT' and netags[arcs[arcs[ni].head-1].head-1] != 'O':\n",
    "                    e2 = complete_e(words, postags, child_dict_list, arcs[arcs[ni].head-1].head-1)\n",
    "                    mi = arcs[arcs[ni].head-1].head-1\n",
    "                    li = mi\n",
    "                    if netags[mi][0] == 'B':\n",
    "                        while netags[mi][0] != 'E':\n",
    "                            mi += 1\n",
    "                        e = ''.join(words[li+1:mi+1])\n",
    "                        e2 += e\n",
    "                    if r in e2:\n",
    "                        e2 = e2[(e2.index(r)+len(r)):]\n",
    "                    if r+e2 in sentence:\n",
    "                        out_file.write(\"%s, %s, %s\\n\" % (e1, r, e2)) #此处三元组的输出格式有待规范\n",
    "                        out_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parse_child_dict(words, postags, arcs):\n",
    "    \"\"\"\n",
    "    为句子中的每个词语维护一个保存句法依存儿子节点的字典\n",
    "    Args:\n",
    "        words: 分词列表\n",
    "        postags: 词性列表\n",
    "        arcs: 句法依存列表\n",
    "    \"\"\"\n",
    "    child_dict_list = []\n",
    "    for index in range(len(words)):\n",
    "        child_dict = dict()\n",
    "        for arc_index in range(len(arcs)):\n",
    "            if arcs[arc_index].head == index + 1:\n",
    "#                 if child_dict.has_key(arcs[arc_index].relation):\n",
    "                if (arcs[arc_index].relation) in child_dict:\n",
    "                    child_dict[arcs[arc_index].relation].append(arc_index)\n",
    "                else:\n",
    "                    child_dict[arcs[arc_index].relation] = []\n",
    "                    child_dict[arcs[arc_index].relation].append(arc_index)\n",
    "        if ('SBV') in child_dict:\n",
    "            print(words[index],child_dict['SBV'])\n",
    "        child_dict_list.append(child_dict)\n",
    "    return child_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_e(words, postags, child_dict_list, word_index):\n",
    "    \"\"\"\n",
    "    完善识别的部分实体\n",
    "    \"\"\"\n",
    "    child_dict = child_dict_list[word_index]\n",
    "    prefix = ''\n",
    "    if ('ATT') in child_dict:\n",
    "        for i in range(len(child_dict['ATT'])):\n",
    "            prefix += complete_e(words, postags, child_dict_list, child_dict['ATT'][i])\n",
    "    \n",
    "    postfix = ''\n",
    "    if postags[word_index] == 'v':\n",
    "        if ('VOB') in child_dict:\n",
    "            postfix += complete_e(words, postags, child_dict_list, child_dict['VOB'][0])\n",
    "        if ('SBV') in child_dict:\n",
    "            prefix = complete_e(words, postags, child_dict_list, child_dict['SBV'][0]) + prefix\n",
    "\n",
    "    return prefix + words[word_index] + postfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是 [0]\n",
      "存储 [3]\n",
      "传输 [6]\n",
      "是 [0]\n",
      "产生 [34]\n",
      "出现 [3]\n",
      "是 [44]\n",
      "出现 [51]\n",
      "是 [3]\n",
      "是 [4]\n",
      "生成 [21]\n",
      "保证 [31]\n",
      "传输 [33]\n",
      "封装 [24]\n",
      "包括 [46]\n",
      "封装 [63]\n",
      "集成 [71, 74]\n",
      "激励 [88]\n",
      "封装 [99]\n",
      "是 [101]\n",
      "封装 [119]\n",
      "是 [154]\n",
      "具 [164]\n",
      "解决 [0]\n",
      "提出 [11]\n",
      "叫 [1]\n",
      "记录 [25]\n",
      "是 [27]\n",
      "参与 [35]\n",
      "是 [12, 14, 20]\n",
      "存储 [29]\n",
      "是 [24, 37]\n",
      "是 [46]\n",
      "是 [56]\n",
      "等同 [62]\n",
      "保证 [68]\n",
      "是 [77, 78]\n",
      "足够 [31]\n",
      "丢失 [45]\n",
      "是 [15]\n",
      "是 [23]\n",
      "授权 [32]\n",
      "是 [4]\n",
      "达成 [11]\n",
      "是 [23]\n",
      "提出 [37]\n",
      "具备 [3]\n",
      "平等 [12]\n",
      "指 [21]\n",
      "比较 [38]\n",
      "平等 [49]\n",
      "是 [50]\n",
      "满足 [54]\n",
      "有 [60]\n",
      "有 [67]\n",
      "是 [5]\n",
      "证明 [8]\n",
      "超过 [15]\n",
      "可能 [47]\n",
      "叫 [3]\n",
      "是 [9]\n",
      "发生 [47]\n",
      "是 [43]\n",
      "频繁 [9]\n",
      "是 [24]\n",
      "认为 [30]\n",
      "切入 [40]\n",
      "– [0]\n",
      "包含 [13]\n",
      "包含 [34]\n",
      "不可逆 [65]\n",
      "是 [2]\n",
      "使 [21]\n",
      "适合 [29]\n",
      "识别 [46]\n",
      "证明 [54]\n",
      "有 [58, 61]\n",
      "进行 [45]\n",
      "使 [56]\n",
      "成为 [72]\n",
      "提出 [4, 9]\n",
      "发表 [24, 26]\n",
      "进行 [44]\n",
      "分散化 [50]\n",
      "称 [56]\n",
      "发表 [65]\n",
      "作为 [1]\n",
      "安全 [6]\n",
      "是 [45]\n",
      "达到 [85]\n",
      "成为 [5]\n",
      "认为 [23, 25]\n",
      "是 [30]\n",
      "是 [33]\n",
      "达到 [55]\n",
      "跳 [81]\n",
      "交换 [88]\n",
      "兑换 [122]\n",
      "得到 [135]\n",
      "使 [142]\n",
      "分配 [163]\n",
      "需要 [180]\n",
      "宣布 [6]\n",
      "利用 [28]\n",
      "开设 [52]\n",
      "举行 [71]\n",
      "发展 [92]\n",
      "获得 [100]\n",
      "使 [107]\n",
      "创 [122]\n",
      "就是 [130]\n",
      "提出 [1]\n",
      "创造 [9]\n",
      "留下 [8]\n",
      "处于 [2, 4, 14, 21]\n",
      "援助 [27]\n",
      "考虑 [6]\n",
      "是 [20]\n",
      "产生 [11]\n",
      "推出 [2]\n",
      "即 [14]\n",
      "刻 [28]\n",
      "是 [3]\n",
      "还有 [12]\n",
      "宣布 [9]\n",
      "取得 [14]\n",
      "肯定 [19]\n",
      "降低 [23]\n",
      "在 [36]\n",
      "增强 [50]\n",
      "是 [59]\n",
      "发布 [67]\n",
      "筹建 [6, 12]\n",
      "是 [19]\n",
      "形成 [0, 6]\n",
      "就是 [28, 35]\n",
      "出发 [41]\n",
      "出发 [52]\n",
      "分为 [0]\n",
      "发行 [5]\n",
      "定义 [9]\n",
      "认为 [32]\n",
      "是 [1]\n",
      "发送 [13]\n",
      "获得 [22]\n",
      "参与 [31]\n",
      "是 [40]\n",
      "有 [62]\n",
      "指定 [1]\n",
      "参与 [35]\n",
      "决定 [69]\n",
      "成为 [76]\n",
      "进行 [86]\n",
      "使用 [1]\n",
      "写入 [30]\n",
      "没有 [35]\n",
      "是 [52]\n",
      "尝试 [60]\n",
      "工业化 [68, 70]\n",
      "在 [77]\n",
      "存在 [11]\n",
      "是 [24]\n",
      "维护 [45]\n",
      "是 [3]\n",
      "公开 [20]\n",
      "通过 [26]\n",
      "查询 [32]\n",
      "透明 [44]\n",
      "采用 [2]\n",
      "自由 [32]\n",
      "起 [57]\n",
      "经过 [6]\n",
      "是 [40]\n",
      "高 [49]\n",
      "遵循 [7]\n",
      "是 [1, 15]\n",
      "判断 [25]\n",
      "有效 [29]\n",
      "让 [36]\n",
      "完成50个句子的抽取\n",
      "让 [0]\n",
      "包括 [30]\n",
      "进行 [39]\n",
      "是 [0]\n",
      "提供 [37]\n",
      "是 [46]\n",
      "是 [53]\n",
      "进行 [57]\n",
      "是 [0]\n",
      "来 [13]\n",
      "深刻 [25]\n",
      "允许 [33]\n",
      "设置 [52]\n",
      "大 [75]\n",
      "让 [1]\n",
      "面临 [17]\n",
      "包括 [14]\n",
      "登记 [27]\n",
      "看待 [1]\n",
      "是 [4]\n",
      "具有 [13]\n",
      "是 [0]\n",
      "数字化 [5]\n",
      "决定 [26]\n",
      "分析 [1]\n",
      "为 [5]\n",
      "获取 [47]\n",
      "调用 [55]\n",
      "计算 [8]\n",
      "需要 [12, 16]\n",
      "高 [29]\n",
      "试用 [40]\n",
      "投入 [0]\n",
      "应用 [20]\n",
      "宣布 [3]\n",
      "涉及 [1]\n",
      "存在 [18]\n",
      "保存 [32]\n",
      "假冒 [62]\n",
      "变 [43]\n",
      "证明 [2]\n",
      "到达 [8]\n",
      "带来 [22, 23, 25, 27]\n",
      "创建 [0]\n",
      "运行 [2]\n",
      "查询 [24]\n",
      "访问 [36]\n",
      "做到 [53]\n",
      "具备 [1]\n",
      "出现 [12]\n",
      "离 [12]\n",
      "设计 [44]\n",
      "掀起 [81]\n",
      "敏感 [1]\n",
      "投身 [11]\n",
      "达 [33]\n",
      "投入 [59]\n",
      "参与 [64]\n",
      "推出 [80]\n",
      "发行 [86]\n",
      "结成 [100]\n",
      "是 [105]\n",
      "是 [122, 124]\n",
      "保守 [1, 7]\n",
      "推出 [43]\n",
      "讨论 [58]\n",
      "带来 [65]\n",
      "管理 [21]\n",
      "分享 [39]\n",
      "经营 [1]\n",
      "时有发生 [10]\n",
      "提供 [15]\n",
      "骗 [20]\n",
      "在于 [28, 41]\n",
      "数字化 [4]\n",
      "出现 [21]\n",
      "真实 [49]\n",
      "同步 [56]\n",
      "有效 [59]\n",
      "是 [0]\n",
      "理赔 [20]\n",
      "投保 [43]\n",
      "投保 [65]\n",
      "是 [0]\n",
      "有 [46]\n",
      "运营 [2]\n",
      "导致 [9]\n",
      "时有发生 [12]\n",
      "采取 [16]\n",
      "开放 [32]\n",
      "多元化 [40]\n",
      "凸显 [48]\n",
      "看来 [53]\n",
      "正是 [57]\n",
      "搬 [71]\n",
      "观察 [101]\n",
      "流向 [116]\n",
      "利用 [6]\n",
      "激活 [19]\n",
      "加深 [51]\n",
      "出现 [65]\n",
      "应用 [1]\n",
      "安全 [10]\n",
      "安全 [13]\n",
      "安全 [18]\n",
      "适合 [27]\n",
      "形成 [33]\n",
      "转移 [44]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #extraction_start(in_file_name, out_file_name, begin_line, end_line)\n",
    "    extraction_start(in_file_name, out_file_name, begin_line, end_line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
