{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyltp import Segmentor, Postagger, Parser, NamedEntityRecognizer# 需装Python后再下载模型，此次运行的模型版本为3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载LTP模型... ...\n",
      "加载模型完毕。\n"
     ]
    }
   ],
   "source": [
    "print(\"正在加载LTP模型... ...\")\n",
    "# Set your own model path\n",
    "MODELDIR=\"E:\\pyltp_model\\ltp_data_v3.4.0\"\n",
    "\n",
    "segmentor = Segmentor()\n",
    "# segmentor.load(os.path.join(MODELDIR, \"cws.model\"))\n",
    "cws_model_path=os.path.join(MODELDIR, \"cws.model\")\n",
    "segmentor.load_with_lexicon(cws_model_path, './dict.txt') #请把字典文件放进当前文件夹\n",
    "               \n",
    "postagger = Postagger()\n",
    "postagger.load(os.path.join(MODELDIR, \"pos.model\"))\n",
    "\n",
    "parser = Parser()\n",
    "parser.load(os.path.join(MODELDIR, \"parser.model\"))\n",
    "\n",
    "recognizer = NamedEntityRecognizer()\n",
    "recognizer.load(os.path.join(MODELDIR, \"ner.model\"))\n",
    "\n",
    "#labeller = SementicRoleLabeller()\n",
    "#labeller.load(os.path.join(MODELDIR, \"srl/\"))\n",
    "\n",
    "print(\"加载模型完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='区块链是分布式数据存储、点对点传输、共识机制、加密算法等计算机技术的新型应用模式'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是 [0]\n",
      "存储 [3]\n",
      "传输 [6]\n"
     ]
    }
   ],
   "source": [
    "    # 切割句子\n",
    "    words = segmentor.segment(sentence)\n",
    "    # 词性标注\n",
    "    postags = postagger.postag(words)\n",
    "    # 命名实体识别\n",
    "    netags = recognizer.recognize(words, postags)\n",
    "    # 依存句法分析，其中已有模型可将句子中的主谓宾等结构抽取出来\n",
    "    arcs = parser.parse(words, postags)\n",
    "\n",
    "    child_dict_list = build_parse_child_dict(words, postags, arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1区块链\n",
      "2是\n",
      "3分布式\n",
      "4数据\n",
      "5存储\n",
      "6、\n",
      "7点对点\n",
      "8传输\n",
      "9、\n",
      "10共识\n",
      "11机制\n",
      "12、\n",
      "13加密\n",
      "14算法\n",
      "15等\n",
      "16计算机\n",
      "17技术\n",
      "18的\n",
      "19新型\n",
      "20应用\n",
      "21模式\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for word in words:\n",
    "    print(str(i)+word)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1n\n",
      "2v\n",
      "3b\n",
      "4n\n",
      "5v\n",
      "6wp\n",
      "7n\n",
      "8v\n",
      "9wp\n",
      "10n\n",
      "11n\n",
      "12wp\n",
      "13v\n",
      "14n\n",
      "15u\n",
      "16n\n",
      "17n\n",
      "18u\n",
      "19b\n",
      "20v\n",
      "21n\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for postag in postags:\n",
    "    print(str(i)+postag)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1->2：SBV\n",
      "2->0：HED\n",
      "3->4：ATT\n",
      "4->5：SBV\n",
      "5->17：ATT\n",
      "6->5：WP\n",
      "7->8：SBV\n",
      "8->5：COO\n",
      "9->11：WP\n",
      "10->11：ATT\n",
      "11->8：COO\n",
      "12->13：WP\n",
      "13->14：ATT\n",
      "14->8：COO\n",
      "15->8：RAD\n",
      "16->17：ATT\n",
      "17->21：ATT\n",
      "18->17：RAD\n",
      "19->21：ATT\n",
      "20->21：ATT\n",
      "21->2：VOB\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for arc in arcs:\n",
    "    print(str(i)+'->'+str(arc.head)+'：'+arc.relation)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'SBV': [0], 'VOB': [20]},\n",
       " {},\n",
       " {'ATT': [2]},\n",
       " {'SBV': [3], 'WP': [5], 'COO': [7]},\n",
       " {},\n",
       " {},\n",
       " {'SBV': [6], 'COO': [10, 13], 'RAD': [14]},\n",
       " {},\n",
       " {},\n",
       " {'WP': [8], 'ATT': [9]},\n",
       " {},\n",
       " {'WP': [11]},\n",
       " {'ATT': [12]},\n",
       " {},\n",
       " {},\n",
       " {'ATT': [4, 15], 'RAD': [17]},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'ATT': [16, 18, 19]}]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'SBV': [0], 'VOB': [20]},\n",
       " {},\n",
       " {'ATT': [2]},\n",
       " {'SBV': [3], 'WP': [5], 'COO': [7]},\n",
       " {},\n",
       " {},\n",
       " {'SBV': [6], 'COO': [10, 13], 'RAD': [14]},\n",
       " {},\n",
       " {},\n",
       " {'WP': [8], 'ATT': [9]},\n",
       " {},\n",
       " {'WP': [11]},\n",
       " {'ATT': [12]},\n",
       " {},\n",
       " {},\n",
       " {'ATT': [4, 15], 'RAD': [17]},\n",
       " {},\n",
       " {},\n",
       " {},\n",
       " {'ATT': [16, 18, 19]}]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parse_child_dict(words, postags, arcs):\n",
    "    \"\"\"\n",
    "    为句子中的每个词语维护一个保存句法依存儿子节点的字典\n",
    "    Args:\n",
    "        words: 分词列表\n",
    "        postags: 词性列表\n",
    "        arcs: 句法依存列表\n",
    "    \"\"\"\n",
    "    child_dict_list = []\n",
    "    for index in range(len(words)):\n",
    "        child_dict = dict()\n",
    "        for arc_index in range(len(arcs)):\n",
    "            if arcs[arc_index].head == index + 1:\n",
    "#                 if child_dict.has_key(arcs[arc_index].relation):\n",
    "                if (arcs[arc_index].relation) in child_dict:\n",
    "                    child_dict[arcs[arc_index].relation].append(arc_index)\n",
    "                else:\n",
    "                    child_dict[arcs[arc_index].relation] = []\n",
    "                    child_dict[arcs[arc_index].relation].append(arc_index)\n",
    "        if ('SBV') in child_dict:\n",
    "            print(words[index],child_dict['SBV'])\n",
    "        child_dict_list.append(child_dict)\n",
    "    return child_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_e(words, postags, child_dict_list, word_index):\n",
    "    \"\"\"\n",
    "    完善识别的部分实体\n",
    "    \"\"\"\n",
    "    child_dict = child_dict_list[word_index]\n",
    "    prefix = ''\n",
    "    if ('ATT') in child_dict:\n",
    "        for i in range(len(child_dict['ATT'])):\n",
    "            prefix = prefix+','+complete_e(words, postags, child_dict_list, child_dict['ATT'][i])\n",
    "    \n",
    "    postfix = ''\n",
    "    if postags[word_index] == 'v':\n",
    "        if ('VOB') in child_dict:\n",
    "            postfix =postfix+','+ complete_e(words, postags, child_dict_list, child_dict['VOB'][0])\n",
    "        if ('SBV') in child_dict:\n",
    "            prefix =prefix+','+ complete_e(words, postags, child_dict_list, child_dict['SBV'][0])\n",
    "\n",
    "    return prefix + words[word_index] + postfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SBV': [0], 'VOB': [20]}\n",
      "区块链\t是\t,,,,分布式数据存储,计算机技术,新型,应用模式\n",
      "\n",
      "{'SBV': [3], 'WP': [5], 'COO': [7]}\n",
      "{'SBV': [6], 'COO': [10, 13], 'RAD': [14]}\n",
      "{'WP': [11]}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "    for index in range(len(postags)):\n",
    "        # 抽取以谓词为中心的事实三元组\n",
    "        if postags[index] == 'v':# 找到谓语\n",
    "            child_dict = child_dict_list[index]\n",
    "            print(child_dict)\n",
    "            # 主谓宾\n",
    "            if   ('SBV') in child_dict and  ('VOB') in child_dict:\n",
    "                e1 = complete_e(words, postags, child_dict_list, child_dict['SBV'][0])\n",
    "                r = words[index]\n",
    "                e2 = complete_e(words, postags, child_dict_list, child_dict['VOB'][0])\n",
    "                print(\"%s\\t%s\\t%s\\n\" % (e1, r, e2)) #此处三元组的输出格式有待规范\n",
    "                # 此部分代码绝密，翻版必究-------------------------------------\n",
    "                if ('COO') in child_dict:\n",
    "                    for i in child_dict['COO']:\n",
    "                        child_dict_list[i]['SBV']=child_dict['SBV']\n",
    "                #----------------------------------------------------\n",
    "                # out_file.flush()\n",
    "            # 定语后置，动宾关系\n",
    "            \n",
    "            if arcs[index].relation == 'ATT':\n",
    "                if  ('VOB') in child_dict:\n",
    "                    e1 = complete_e(words, postags, child_dict_list, arcs[index].head - 1)\n",
    "                    r = words[index]\n",
    "                    e2 = complete_e(words, postags, child_dict_list, child_dict['VOB'][0])\n",
    "                    temp_string = r+e2\n",
    "                    if temp_string == e1[:len(temp_string)]:\n",
    "                        e1 = e1[len(temp_string):]\n",
    "                    if temp_string not in e1:\n",
    "                        print(\"%s\\t%s\\t%s\\n\" % (e1, r, e2)) #此处三元组的输出格式有待规范\n",
    "                        # out_file.flush()\n",
    "            # 含有介宾关系的主谓动补关系\n",
    "            if  ('SBV') in child_dict and  ('CMP') in child_dict:\n",
    "                #e1 = words[child_dict['SBV'][0]]\n",
    "                e1 = complete_e(words, postags, child_dict_list, child_dict['SBV'][0])\n",
    "                cmp_index = child_dict['CMP'][0]\n",
    "                r = words[index] + words[cmp_index]\n",
    "                if  ('POB') in child_dict_list[cmp_index]:\n",
    "                    e2 = complete_e(words, postags, child_dict_list, child_dict_list[cmp_index]['POB'][0])\n",
    "                    print(\"%s\\t%s\\t%s\\n\" % (e1, r, e2)) #此处三元组的输出格式有待规范\n",
    "                    # out_file.flush()\n",
    "\n",
    "        # 尝试抽取命名实体有关的三元组\n",
    "        if netags[index][0] == 'S' or netags[index][0] == 'B':\n",
    "            ni = index\n",
    "            if netags[ni][0] == 'B':\n",
    "                while netags[ni][0] != 'E':\n",
    "                    ni += 1\n",
    "                e1 = ''.join(words[index:ni+1])\n",
    "            else:\n",
    "                e1 = words[ni]\n",
    "            if arcs[ni].relation == 'ATT' and postags[arcs[ni].head-1] == 'n' and netags[arcs[ni].head-1] == 'O':\n",
    "                r = complete_e(words, postags, child_dict_list, arcs[ni].head-1)\n",
    "                if e1 in r:\n",
    "                    r = r[(r.index(e1)+len(e1)):]\n",
    "                if arcs[arcs[ni].head-1].relation == 'ATT' and netags[arcs[arcs[ni].head-1].head-1] != 'O':\n",
    "                    e2 = complete_e(words, postags, child_dict_list, arcs[arcs[ni].head-1].head-1)\n",
    "                    mi = arcs[arcs[ni].head-1].head-1\n",
    "                    li = mi\n",
    "                    if netags[mi][0] == 'B':\n",
    "                        while netags[mi][0] != 'E':\n",
    "                            mi += 1\n",
    "                        e = ''.join(words[li+1:mi+1])\n",
    "                        e2 += e\n",
    "                    if r in e2:\n",
    "                        e2 = e2[(e2.index(r)+len(r)):]\n",
    "                    if r+e2 in sentence:\n",
    "                        print(\"%s\\t%s\\t%s\\n\" % (e1, r, e2)) #此处三元组的输出格式有待规范\n",
    "                        # out_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WP'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc.relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
